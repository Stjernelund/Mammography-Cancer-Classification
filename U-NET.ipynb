{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses a VGG-16 U-Net Convolutional Network to segment abnormalities from mammographies of breasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = # TODO\n",
    "NUM_EPOCHS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(y_true, y_pred):\n",
    "    \n",
    "    intersection = (y_true * y_pred).sum()\n",
    "    union = y_true.sum() + y_pred.sum() - intersection\n",
    "    x = (intersection + 1e-15) / (union + 1e-15)\n",
    "    x = x.astype(np.float32)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input is output from previous layer\n",
    "#num_filters is number of feature channels in the convolutional layer\n",
    "#skip_features are the appropriate size feature maps from the pre-trained VGG16 encoder.\n",
    "def convolutional_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    " \n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    " \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = convolutional_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input shape is (height,   width,   channels)\n",
    "def build_vgg16_unet(input_shape):\n",
    "    inputs = Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "#include_top = False means we don't want the last layer of the VGG16 model\n",
    "#weights = \"imagenet\" means we want the weights of the VGG16 model trained on imagenet\n",
    "#input_tensor = inputs means we want the input of the VGG16 model to be the input of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 16s 0us/step\n",
      "58900480/58889256 [==============================] - 16s 0us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'decoder_block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     input_shape \u001b[39m=\u001b[39m (\u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     model \u001b[39m=\u001b[39m build_vgg16_unet(input_shape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;32m/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb Cell 10\u001b[0m in \u001b[0;36mbuild_vgg16_unet\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m b1 \u001b[39m=\u001b[39m vgg16\u001b[39m.\u001b[39mget_layer(\u001b[39m\"\u001b[39m\u001b[39mblock5_conv3\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39moutput         \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m\"\"\" Decoder \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m d1 \u001b[39m=\u001b[39m decoder_block(b1, s4, \u001b[39m512\u001b[39m)                    \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m d2 \u001b[39m=\u001b[39m decoder_block(d1, s3, \u001b[39m256\u001b[39m)                     \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audunlien/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/project/U-NET.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m d3 \u001b[39m=\u001b[39m decoder_block(d2, s2, \u001b[39m128\u001b[39m)                     \n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_block' is not defined"
     ]
    }
   ],
   "source": [
    "def build_vgg16_unet(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    " \n",
    "    \"\"\" Pre-trained VGG16 Model \"\"\"\n",
    "    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    " \n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = vgg16.get_layer(\"block1_conv2\").output         \n",
    "    s2 = vgg16.get_layer(\"block2_conv2\").output         \n",
    "    s3 = vgg16.get_layer(\"block3_conv3\").output         \n",
    "    s4 = vgg16.get_layer(\"block4_conv3\").output         \n",
    " \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = vgg16.get_layer(\"block5_conv3\").output         \n",
    " \n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)                    \n",
    "    d2 = decoder_block(d1, s3, 256)                     \n",
    "    d3 = decoder_block(d2, s2, 128)                     \n",
    "    d4 = decoder_block(d3, s1, 64)                      \n",
    " \n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    " \n",
    "    model = Model(inputs, outputs, name=\"VGG16_U-Net\")\n",
    "    return model\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (512, 512, 3)\n",
    "    model = build_vgg16_unet(input_shape)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = self.makeTFDataset(\n",
    "    shuffle=True,\n",
    "    augment=True,\n",
    "    x_paths_list=train_x,\n",
    "    y_paths_list=train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate train and test steps per epoch.\n",
    "train_steps = len(train_x) // BATCH_SIZE\n",
    "test_steps = len(test_x) // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=test_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ef97189062d9f6aba917ee8bd3cd97ea5506606191f45c3060d07bb17286a4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
